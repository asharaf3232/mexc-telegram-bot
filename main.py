# -*- coding: utf-8 -*-

# --- Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© --- #
import ccxt.async_support as ccxt
import pandas as pd
import pandas_ta as ta
import asyncio
import os
import logging
import json
import re
import time
import sqlite3
from datetime import datetime
from zoneinfo import ZoneInfo
from telegram import Update, ReplyKeyboardMarkup, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.constants import ParseMode
from telegram.ext import Application, CommandHandler, ContextTypes, MessageHandler, filters, CallbackQueryHandler
from telegram.error import BadRequest

# [NEW] Gracefully handle optional scipy import
try:
    from scipy.signal import find_peaks
    SCIPY_AVAILABLE = True
except ImportError:
    SCIPY_AVAILABLE = False
    logging.warning("Library 'scipy' not found. RSI Divergence strategy will be disabled.")


# --- Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© --- #
TELEGRAM_BOT_TOKEN = os.getenv('TELEGRAM_BOT_TOKEN', 'YOUR_BOT_TOKEN_HERE')
TELEGRAM_CHAT_ID = os.getenv('TELEGRAM_CHAT_ID', 'YOUR_CHAT_ID_HERE')

if TELEGRAM_BOT_TOKEN == 'YOUR_BOT_TOKEN_HERE' or TELEGRAM_CHAT_ID == 'YOUR_CHAT_ID_HERE':
    print("FATAL ERROR: Please set your Telegram Token and Chat ID.")
    exit()

# --- Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø¨ÙˆØª --- #
EXCHANGES_TO_SCAN = ['binance', 'okx', 'bybit', 'kucoin', 'gate', 'mexc']
TIMEFRAME = '15m'
SCAN_INTERVAL_SECONDS = 900
TRACK_INTERVAL_SECONDS = 120
SETTINGS_FILE = 'settings.json'

# [DATABASE FIX v2] Point to a shared temporary directory to resolve process isolation issues
DB_FILE = '/tmp/trading_bot_v12.db'

EGYPT_TZ = ZoneInfo("Africa/Cairo")

# --- Ø¥Ø¹Ø¯Ø§Ø¯ Ù…Ø³Ø¬Ù„ Ø§Ù„Ø£Ø­Ø¯Ø§Ø« (Logger) --- #
logging.basicConfig(format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', level=logging.INFO, handlers=[logging.FileHandler("bot_v12.log"), logging.StreamHandler()])
logging.getLogger('httpx').setLevel(logging.WARNING)
logging.getLogger('apscheduler').setLevel(logging.WARNING)
logging.getLogger('telegram').setLevel(logging.WARNING)


# --- Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø­Ø§Ù„Ø© Ø§Ù„Ø¹Ø§Ù…Ø© Ù„Ù„Ø¨ÙˆØª --- #
bot_data = {"exchanges": {}, "last_signal_time": {}, "settings": {}, "status_snapshot": {"last_scan_start_time": "N/A", "last_scan_end_time": "N/A", "markets_found": 0, "signals_found": 0, "active_trades_count": 0, "scan_in_progress": False}}

# --- Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª --- #
DEFAULT_SETTINGS = {
    "virtual_portfolio_balance_usdt": 1000.0, "virtual_trade_size_percentage": 5.0, "max_concurrent_trades": 5, "top_n_symbols_by_volume": 250, "concurrent_workers": 10, "market_regime_filter_enabled": True,
    "active_scanners": ["momentum_breakout", "breakout_squeeze"],
    "use_dynamic_risk_management": True, "atr_period": 14, "atr_sl_multiplier": 2.0, "risk_reward_ratio": 1.5,
    "take_profit_percentage": 4.0, "stop_loss_percentage": 2.0, "trailing_sl_enabled": True, "trailing_sl_activate_percent": 2.0, "trailing_sl_percent": 1.5,
    "momentum_breakout": {"vwap_period": 14, "macd_fast": 12, "macd_slow": 26, "macd_signal": 9, "bbands_period": 20, "bbands_stddev": 2.0, "rsi_period": 14, "rsi_max_level": 68},
    "mean_reversion": {"bbands_period": 20, "bbands_stddev": 2.0, "rsi_period": 14, "rsi_oversold_level": 30},
    "breakout_squeeze": {"bbands_period": 20, "bbands_stddev": 2.0, "squeeze_threshold_percent": 3.5},
    "rsi_divergence": {"rsi_period": 14, "lookback_period": 35, "peak_trough_lookback": 5}
}

def load_settings():
    if os.path.exists(SETTINGS_FILE):
        with open(SETTINGS_FILE, 'r') as f: bot_data["settings"] = json.load(f)
        updated = False
        for key, value in DEFAULT_SETTINGS.items():
            if key not in bot_data["settings"]:
                bot_data["settings"][key] = value; updated = True
            elif isinstance(value, dict):
                 for sub_key, sub_value in value.items():
                     if sub_key not in bot_data["settings"].get(key, {}):
                         bot_data["settings"][key][sub_key] = sub_value; updated = True
        if updated: save_settings()
    else:
        bot_data["settings"] = DEFAULT_SETTINGS
        save_settings()
    logging.info("Settings loaded successfully.")

def save_settings():
    with open(SETTINGS_FILE, 'w') as f: json.dump(bot_data["settings"], f, indent=4)
    logging.info("Settings saved successfully.")

# --- Ø¥Ø¯Ø§Ø±Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª --- #
def init_database():
    conn = sqlite3.connect(DB_FILE)
    cursor = conn.cursor()
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS trades (id INTEGER PRIMARY KEY AUTOINCREMENT, timestamp TEXT, exchange TEXT, symbol TEXT, entry_price REAL, take_profit REAL, stop_loss REAL, quantity REAL, entry_value_usdt REAL, status TEXT, exit_price REAL, closed_at TEXT, exit_value_usdt REAL, pnl_usdt REAL, trailing_sl_active BOOLEAN, highest_price REAL, reason TEXT)
    ''')
    conn.commit()
    conn.close()
    logging.info(f"Database initialized successfully at: {DB_FILE}")

def log_recommendation_to_db(signal):
    conn = sqlite3.connect(DB_FILE)
    cursor = conn.cursor()
    cursor.execute('INSERT INTO trades (timestamp, exchange, symbol, entry_price, take_profit, stop_loss, quantity, entry_value_usdt, status, trailing_sl_active, highest_price, reason) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)', (signal['timestamp'].strftime('%Y-%m-%d %H:%M:%S'), signal['exchange'], signal['symbol'], signal['entry_price'], signal['take_profit'], signal['stop_loss'], signal['quantity'], signal['entry_value_usdt'], 'Ù†Ø´Ø·Ø©', False, signal['entry_price'], signal['reason']))
    trade_id = cursor.lastrowid
    conn.commit()
    conn.close()
    return trade_id

# --- ÙˆØ­Ø¯Ø§Øª Ø§Ù„Ù…Ø³Ø­ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø© (Scanners) --- #
def analyze_momentum_breakout(df, params):
    try:
        df.ta.vwap(append=True); df.ta.bbands(length=params['bbands_period'], std=params['bbands_stddev'], append=True); df.ta.macd(fast=params['macd_fast'], slow=params['macd_slow'], signal=params['macd_signal'], append=True); df.ta.rsi(length=params['rsi_period'], append=True)
        bbu_col, macd_col, macds_col, rsi_col = f"BBU_{params['bbands_period']}_{params['bbands_stddev']}", f"MACD_{params['macd_fast']}_{params['macd_slow']}_{params['macd_signal']}", f"MACDs_{params['macd_fast']}_{params['macd_slow']}_{params['macd_signal']}", f"RSI_{params['rsi_period']}"
        last, prev = df.iloc[-2], df.iloc[-3]
        if (prev[macd_col] <= prev[macds_col] and last[macd_col] > last[macds_col] and last['close'] > last[bbu_col] and last['close'] > last["VWAP_D"] and last[rsi_col] < params['rsi_max_level']):
             return {"reason": "Momentum Breakout", "type": "long"}
    except Exception: return None
    return None

def analyze_mean_reversion(df, params):
    try:
        df.ta.bbands(length=params['bbands_period'], std=params['bbands_stddev'], append=True); df.ta.rsi(length=params['rsi_period'], append=True)
        bbl_col, rsi_col = f"BBL_{params['bbands_period']}_{params['bbands_stddev']}", f"RSI_{params['rsi_period']}"
        last = df.iloc[-2]
        if (last['close'] < last[bbl_col] and last[rsi_col] < params['rsi_oversold_level']):
            return {"reason": "Mean Reversion (Oversold Bounce)", "type": "long"}
    except Exception: return None
    return None

def analyze_breakout_squeeze(df, params):
    try:
        df.ta.bbands(length=params['bbands_period'], std=params['bbands_stddev'], append=True)
        bbu_col, bbl_col = f"BBU_{params['bbands_period']}_{params['bbands_stddev']}", f"BBL_{params['bbands_period']}_{params['bbands_stddev']}"
        df['bb_width'] = (df[bbu_col] - df[bbl_col]) / df['close'] * 100
        last, prev = df.iloc[-2], df.iloc[-3]
        if prev['bb_width'] < params['squeeze_threshold_percent'] and last['close'] > last[bbu_col]:
            return {"reason": f"Breakout Squeeze (BBW < {params['squeeze_threshold_percent']}%)", "type": "long"}
    except Exception: return None
    return None

def find_divergence_points(series, lookback):
    if not SCIPY_AVAILABLE:
        return [], []
    peaks, _ = find_peaks(series, distance=lookback)
    troughs, _ = find_peaks(-series, distance=lookback)
    return peaks, troughs

def analyze_rsi_divergence(df, params):
    if not SCIPY_AVAILABLE:
        return None
    try:
        rsi_col = f"RSI_{params['rsi_period']}"
        df.ta.rsi(length=params['rsi_period'], append=True, col_names=(rsi_col,))
        if df[rsi_col].isnull().all(): return None
        
        subset = df.iloc[-params['lookback_period']:].copy()
        
        price_peaks_idx, _ = find_divergence_points(subset['high'], params['peak_trough_lookback'])
        price_troughs_idx, _ = find_divergence_points(-subset['low'], params['peak_trough_lookback'])
        rsi_peaks_idx, _ = find_divergence_points(subset[rsi_col], params['peak_trough_lookback'])
        rsi_troughs_idx, _ = find_divergence_points(-subset[rsi_col], params['peak_trough_lookback'])
        
        if len(price_troughs_idx) >= 2 and len(rsi_troughs_idx) >= 2:
            p_low1_idx, p_low2_idx = price_troughs_idx[-2], price_troughs_idx[-1]
            r_low1_idx, r_low2_idx = rsi_troughs_idx[-2], rsi_troughs_idx[-1]
            if subset.iloc[p_low2_idx]['low'] < subset.iloc[p_low1_idx]['low'] and subset.iloc[r_low2_idx][rsi_col] > subset.iloc[r_low1_idx][rsi_col]:
                return {"reason": "Bullish RSI Divergence", "type": "long"}

        if len(price_peaks_idx) >= 2 and len(rsi_peaks_idx) >= 2:
            p_high1_idx, p_high2_idx = price_peaks_idx[-2], price_peaks_idx[-1]
            r_high1_idx, r_high2_idx = rsi_peaks_idx[-2], rsi_peaks_idx[-1]
            if subset.iloc[p_high2_idx]['high'] > subset.iloc[p_high1_idx]['high'] and subset.iloc[r_high2_idx][rsi_col] < subset.iloc[r_high1_idx][rsi_col]:
                return {"reason": "Bearish RSI Divergence", "type": "bearish_signal"}
    except Exception as e:
        logging.warning(f"RSI Divergence analysis failed during execution: {e}")
    return None

SCANNERS = {
    "momentum_breakout": analyze_momentum_breakout,
    "mean_reversion": analyze_mean_reversion,
    "breakout_squeeze": analyze_breakout_squeeze,
    "rsi_divergence": analyze_rsi_divergence,
}

# --- Ø§Ù„Ø¯ÙˆØ§Ù„ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ù„Ù„Ø¨ÙˆØª --- #
async def initialize_exchanges():
    async def connect(ex_id):
        exchange = getattr(ccxt, ex_id)({'enableRateLimit': True})
        try: await exchange.load_markets(); bot_data["exchanges"][ex_id] = exchange; logging.info(f"Connected to {ex_id}")
        except Exception as e: logging.error(f"Failed for {ex_id}: {e}"); await exchange.close()
    await asyncio.gather(*[connect(ex_id) for ex_id in EXCHANGES_TO_SCAN])

async def aggregate_top_movers():
    all_tickers = []
    async def fetch(ex_id, ex):
        try: return [dict(t, exchange=ex_id) for t in (await ex.fetch_tickers()).values()]
        except Exception: return []
    results = await asyncio.gather(*[fetch(ex_id, ex) for ex_id, ex in bot_data["exchanges"].items()])
    for res in results: all_tickers.extend(res)
    usdt_tickers = [t for t in all_tickers if t.get('symbol') and 'USDT' in t['symbol'].upper() and not any(k in t['symbol'].upper() for k in ['UP','DOWN','3L','3S','BEAR','BULL'])]
    sorted_tickers = sorted(usdt_tickers, key=lambda t: t.get('quoteVolume', 0) or 0, reverse=True)
    unique_symbols = {t['symbol']: {'exchange': t['exchange'], 'symbol': t['symbol']} for t in sorted_tickers}
    final_list = list(unique_symbols.values())[:bot_data["settings"]['top_n_symbols_by_volume']]
    bot_data['status_snapshot']['markets_found'] = len(final_list)
    return final_list

async def worker(queue, results_list, settings):
    while not queue.empty():
        try:
            market_info = await queue.get()
            exchange = bot_data["exchanges"].get(market_info['exchange'])
            if not exchange or not settings.get('active_scanners'): continue

            ohlcv = await exchange.fetch_ohlcv(market_info['symbol'], TIMEFRAME, limit=150)
            if len(ohlcv) < 50: queue.task_done(); continue
            df = pd.DataFrame(ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume']); df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms'); df.set_index('timestamp', inplace=True)
            df.ta.atr(length=settings['atr_period'], append=True)

            for scanner_name in settings['active_scanners']:
                analysis_result = SCANNERS.get(scanner_name, lambda d, p: None)(df, settings.get(scanner_name, {}))
                if analysis_result and analysis_result.get("type") == "long":
                    entry_price = df.iloc[-2]['close']
                    current_atr = df.iloc[-2].get(f"ATRr_{settings['atr_period']}", 0)
                    
                    if settings.get("use_dynamic_risk_management", False) and current_atr > 0 and not pd.isna(current_atr):
                        risk_per_unit = current_atr * settings['atr_sl_multiplier']
                        stop_loss = entry_price - risk_per_unit
                        take_profit = entry_price + (risk_per_unit * settings['risk_reward_ratio'])
                    else:
                        stop_loss = entry_price * (1 - settings['stop_loss_percentage'] / 100)
                        take_profit = entry_price * (1 + settings['take_profit_percentage'] / 100)

                    signal = {"symbol": market_info['symbol'], "exchange": market_info['exchange'].capitalize(), "entry_price": entry_price, "take_profit": take_profit, "stop_loss": stop_loss, "timestamp": df.index[-2], "reason": analysis_result['reason']}
                    results_list.append(signal)
                    break 
            queue.task_done()
        except Exception: queue.task_done()

async def perform_scan(context: ContextTypes.DEFAULT_TYPE):
    status = bot_data['status_snapshot']
    status.update({"scan_in_progress": True, "last_scan_start_time": datetime.now(EGYPT_TZ).strftime('%Y-%m-%d %H:%M:%S'), "signals_found": 0})
    settings = bot_data["settings"]
    
    conn = sqlite3.connect(DB_FILE); cursor = conn.cursor(); cursor.execute("SELECT COUNT(*) FROM trades WHERE status = 'Ù†Ø´Ø·Ø©'"); active_trades_count = cursor.fetchone()[0]; conn.close()
    if active_trades_count >= settings.get("max_concurrent_trades", 3):
        logging.info("Skipping scan: Max concurrent trades limit reached."); status['scan_in_progress'] = False; return

    if settings.get('market_regime_filter_enabled', True) and not await check_market_regime():
        logging.info("Skipping scan: Bearish market regime detected."); status['scan_in_progress'] = False; return
    
    top_markets = await aggregate_top_movers()
    if not top_markets: logging.info("No markets to scan."); status['scan_in_progress'] = False; return
    
    queue = asyncio.Queue(); [await queue.put(market) for market in top_markets]
    signals = []; worker_tasks = [asyncio.create_task(worker(queue, signals, settings)) for _ in range(settings['concurrent_workers'])]
    await queue.join(); [task.cancel() for task in worker_tasks]

    last_signal_time = bot_data['last_signal_time']
    for signal in signals:
        if active_trades_count >= settings.get("max_concurrent_trades", 3): break
        symbol = signal['symbol']; current_time = time.time()
        if symbol not in last_signal_time or (current_time - last_signal_time.get(symbol, 0)) > (SCAN_INTERVAL_SECONDS * 4):
            trade_amount_usdt = settings["virtual_portfolio_balance_usdt"] * (settings["virtual_trade_size_percentage"] / 100)
            signal.update({'quantity': trade_amount_usdt / signal['entry_price'], 'entry_value_usdt': trade_amount_usdt})
            trade_id = log_recommendation_to_db(signal); signal['trade_id'] = trade_id
            await send_telegram_message(context.bot, signal, is_new=True)
            last_signal_time[symbol] = current_time
            status['signals_found'] += 1; active_trades_count += 1
            
    status['last_scan_end_time'] = datetime.now(EGYPT_TZ).strftime('%Y-%m-%d %H:%M:%S'); status['scan_in_progress'] = False

async def send_telegram_message(bot, signal_data, is_new=False, status_update=None, update_type=None):
    message = ""; keyboard = None
    if is_new:
        message = (f"âœ… *Ù…Ø­Ø§ÙƒØ§Ø© ØµÙÙ‚Ø© Ø¬Ø¯ÙŠØ¯Ø©* âœ…\n\n*Ø§Ù„Ø¹Ù…Ù„Ø©:* `{signal_data['symbol']}` | *Ø§Ù„Ù…Ù†ØµØ©:* `{signal_data['exchange']}`\n*Ø±Ù‚Ù… Ø§Ù„ØµÙÙ‚Ø©:* `{signal_data['trade_id']}`\n\n*Ø³Ø¨Ø¨ Ø§Ù„Ø¯Ø®ÙˆÙ„:* `{signal_data['reason']}`\n*Ø³Ø¹Ø± Ø§Ù„Ø¯Ø®ÙˆÙ„:* `${signal_data['entry_price']:,.4f}`\n*Ù‚ÙŠÙ…Ø© Ø§Ù„ØµÙÙ‚Ø©:* `${signal_data['entry_value_usdt']:,.2f}`\n\nğŸ¯ *Ø¬Ù†ÙŠ Ø§Ù„Ø£Ø±Ø¨Ø§Ø­:* `${signal_data['take_profit']:,.4f}`\nğŸ›‘ *ÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø±Ø©:* `${signal_data['stop_loss']:,.4f}`")
        keyboard = InlineKeyboardMarkup([[InlineKeyboardButton("ğŸ” Ù…ØªØ§Ø¨Ø¹Ø© Ø­ÙŠØ©", callback_data=f"check_{signal_data['trade_id']}")]])
    elif status_update in ['Ù†Ø§Ø¬Ø­Ø©', 'ÙØ§Ø´Ù„Ø©']:
        pnl_percent = (signal_data['pnl_usdt'] / signal_data['entry_value_usdt'] * 100) if signal_data['entry_value_usdt'] else 0
        icon, title, pnl_label = ("ğŸ¯", "Ù‡Ø¯Ù Ù…Ø­Ù‚Ù‚!", "Ø§Ù„Ø±Ø¨Ø­") if status_update == 'Ù†Ø§Ø¬Ø­Ø©' else ("ğŸ›‘", "ØªÙ… ØªÙØ¹ÙŠÙ„ ÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø±Ø©", "Ø§Ù„Ø®Ø³Ø§Ø±Ø©")
        message = f"{icon} *{title}* {icon}\n\n*Ø§Ù„Ø¹Ù…Ù„Ø©:* `{signal_data['symbol']}`\n*{pnl_label}:* `~${abs(signal_data['pnl_usdt']):.2f} ({pnl_percent:+.2f}%)`"
    elif update_type == 'tsl_activation': message = f"ğŸ”’ *ØªØ£Ù…ÙŠÙ† Ø£Ø±Ø¨Ø§Ø­* ğŸ”’\n\n*Ø§Ù„Ø¹Ù…Ù„Ø©:* `{signal_data['symbol']}`\nØªÙ… Ù†Ù‚Ù„ ÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø±Ø© Ø¥Ù„Ù‰ `${signal_data['stop_loss']:,.4f}`."
    if message: await bot.send_message(chat_id=TELEGRAM_CHAT_ID, text=message, parse_mode=ParseMode.MARKDOWN, reply_markup=keyboard)

async def track_open_trades(context: ContextTypes.DEFAULT_TYPE):
    conn = sqlite3.connect(DB_FILE); conn.row_factory = sqlite3.Row; cursor = conn.cursor()
    cursor.execute("SELECT * FROM trades WHERE status = 'Ù†Ø´Ø·Ø©'")
    active_trades = [dict(row) for row in cursor.fetchall()]; conn.close()
    bot_data['status_snapshot']['active_trades_count'] = len(active_trades)
    if not active_trades: return
    
    async def check_trade(trade):
        exchange = bot_data["exchanges"].get(trade['exchange'].lower())
        if not exchange: return None
        try:
            ticker = await exchange.fetch_ticker(trade['symbol']); current_price = ticker.get('last') or ticker.get('close')
            if not current_price: return None
            if current_price >= trade['take_profit']: return {'id': trade['id'], 'status': 'Ù†Ø§Ø¬Ø­Ø©', 'exit_price': current_price}
            if current_price <= trade['stop_loss']: return {'id': trade['id'], 'status': 'ÙØ§Ø´Ù„Ø©', 'exit_price': current_price}
            
            settings = bot_data["settings"]
            if settings.get('trailing_sl_enabled', False):
                highest_price = max(trade.get('highest_price', current_price), current_price)
                if not trade.get('trailing_sl_active') and current_price >= trade['entry_price'] * (1 + settings['trailing_sl_activate_percent'] / 100):
                    new_sl = trade['entry_price'] * (1 + (settings.get('trailing_sl_activate_percent', 2.0) - settings.get('trailing_sl_percent', 1.5)) / 100)
                    if new_sl > trade['stop_loss']:
                        return {'id': trade['id'], 'status': 'update_tsl', 'new_sl': new_sl, 'highest_price': highest_price}
                elif trade.get('trailing_sl_active'):
                    new_sl = highest_price * (1 - settings['trailing_sl_percent'] / 100)
                    if new_sl > trade['stop_loss']: return {'id': trade['id'], 'status': 'update_sl', 'new_sl': new_sl, 'highest_price': highest_price}
                    elif highest_price > trade.get('highest_price', 0): return {'id': trade['id'], 'status': 'update_peak', 'highest_price': highest_price}
        except Exception: pass
        return None

    results = await asyncio.gather(*[check_trade(trade) for trade in active_trades])
    updates_to_db = []; portfolio_pnl = 0.0
    for result in filter(None, results):
        original_trade = next((t for t in active_trades if t['id'] == result['id']), None)
        if not original_trade: continue
        
        status = result['status']
        if status in ['Ù†Ø§Ø¬Ø­Ø©', 'ÙØ§Ø´Ù„Ø©']:
            pnl = (result['exit_price'] - original_trade['entry_price']) * original_trade['quantity']; portfolio_pnl += pnl
            closed_at_str = datetime.now(EGYPT_TZ).strftime('%Y-%m-%d %H:%M:%S')
            updates_to_db.append(("UPDATE trades SET status=?, exit_price=?, closed_at=?, exit_value_usdt=?, pnl_usdt=? WHERE id=?", (status, result['exit_price'], closed_at_str, result['exit_price'] * original_trade['quantity'], pnl, result['id'])))
            await send_telegram_message(context.bot, {**original_trade, **result, 'pnl_usdt': pnl}, status_update=status)
        elif status == 'update_tsl':
            updates_to_db.append(("UPDATE trades SET stop_loss=?, highest_price=?, trailing_sl_active=? WHERE id=?", (result['new_sl'], result['highest_price'], True, result['id'])))
            await send_telegram_message(context.bot, {**original_trade, **result}, update_type='tsl_activation')
        elif status == 'update_sl': updates_to_db.append(("UPDATE trades SET stop_loss=?, highest_price=? WHERE id=?", (result['new_sl'], result['highest_price'], result['id'])))
        elif status == 'update_peak': updates_to_db.append(("UPDATE trades SET highest_price=? WHERE id=?", (result['highest_price'], result['id'])))
    
    if updates_to_db: conn = sqlite3.connect(DB_FILE); cursor = conn.cursor(); [cursor.execute(q, p) for q, p in updates_to_db]; conn.commit(); conn.close()
    if portfolio_pnl != 0.0: bot_data['settings']['virtual_portfolio_balance_usdt'] += portfolio_pnl; save_settings(); logging.info(f"Portfolio balance updated by ${portfolio_pnl:.2f}.")

async def check_market_regime():
    try:
        binance = bot_data["exchanges"].get('binance')
        if not binance: return True
        ohlcv = await binance.fetch_ohlcv('BTC/USDT', '4h', limit=55)
        df = pd.DataFrame(ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])
        df['sma50'] = ta.sma(df['close'], length=50)
        return df['close'].iloc[-1] > df['sma50'].iloc[-1]
    except Exception: return True

async def fetch_historical_data_paginated(symbol, timeframe, limit):
    logging.info(f"Fetching {limit} candles for {symbol}...")
    exchange = ccxt.binance()
    all_ohlcv = []
    try:
        since = None
        while len(all_ohlcv) < limit:
            fetch_limit = min(limit - len(all_ohlcv), 1000)
            ohlcv = await exchange.fetch_ohlcv(symbol, timeframe, since=since, limit=fetch_limit)
            if not ohlcv: break
            all_ohlcv = ohlcv + all_ohlcv
            since = ohlcv[0][0] - 1
        
        df = pd.DataFrame(all_ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])
        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
        df.set_index('timestamp', inplace=True)
        df.sort_index(inplace=True)
        df = df.iloc[-limit:]
        logging.info(f"Successfully fetched {len(df)} candles for {symbol}.")
        return df
    except Exception as e:
        logging.error(f"Error fetching paginated data for {symbol}: {e}")
        return None
    finally:
        await exchange.close()

def analyze_backtest_results(trades, symbol, timeframe, limit):
    if not trades: return (f"\n*Ù„Ù… ÙŠØªÙ… ØªÙ†ÙÙŠØ° Ø£ÙŠ ØµÙÙ‚Ø§Øª.*\n\n"
                           f"Ù‚Ø¯ ÙŠÙƒÙˆÙ† Ù‡Ø°Ø§ Ø¨Ø³Ø¨Ø¨ Ø£Ù† Ø´Ø±ÙˆØ· Ø§Ù„Ù…Ø§Ø³Ø­Ø§Øª Ø§Ù„Ù†Ø´Ø·Ø© Ù„Ù… ØªØªØ­Ù‚Ù‚ Ø®Ù„Ø§Ù„ Ø§Ù„ÙØªØ±Ø© Ø§Ù„Ù…Ø®ØªØ§Ø±Ø©. "
                           f"Ø¬Ø±Ø¨ ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ù…Ø¹Ø§ÙŠÙŠØ±ØŒ Ø£Ùˆ ØªØºÙŠÙŠØ± Ø§Ù„Ø¥Ø·Ø§Ø± Ø§Ù„Ø²Ù…Ù†ÙŠØŒ Ø£Ùˆ Ø²ÙŠØ§Ø¯Ø© Ø¹Ø¯Ø¯ Ø§Ù„Ø´Ù…ÙˆØ¹.")
    df_trades = pd.DataFrame(trades)
    total_trades = len(df_trades); wins = df_trades[df_trades['status'] == 'Take Profit']; losses = df_trades[df_trades['status'] == 'Stop Loss']
    win_rate = (len(wins) / total_trades) * 100 if total_trades > 0 else 0
    total_pnl = df_trades['pnl'].sum(); avg_win = wins['pnl'].mean() if len(wins) > 0 else 0; avg_loss = losses['pnl'].mean() if len(losses) > 0 else 0
    risk_reward_ratio = abs(avg_win / avg_loss) if avg_loss != 0 else float('inf')
    df_trades['cumulative_pnl'] = df_trades['pnl'].cumsum(); df_trades['peak'] = df_trades['cumulative_pnl'].cummax()
    df_trades['drawdown'] = df_trades['peak'] - df_trades['cumulative_pnl']; max_drawdown = df_trades['drawdown'].max()
    report = (
        f"--- ğŸ“œ *ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠ* ---\n\n*Ø§Ù„Ø¹Ù…Ù„Ø©:* `{symbol}` | *Ø§Ù„Ø¥Ø·Ø§Ø± Ø§Ù„Ø²Ù…Ù†ÙŠ:* `{timeframe}` | *Ø§Ù„Ø´Ù…ÙˆØ¹:* `{limit}`\n\n"
        f"â–«ï¸ *Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„ØµÙÙ‚Ø§Øª:* `{total_trades}`\nâœ… *Ø§Ù„Ø±Ø§Ø¨Ø­Ø©:* `{len(wins)}` | âŒ *Ø§Ù„Ø®Ø§Ø³Ø±Ø©:* `{len(losses)}`\n"
        f"ğŸ“ˆ *Ù…Ø¹Ø¯Ù„ Ø§Ù„Ù†Ø¬Ø§Ø­:* `{win_rate:.2f}%`\n\nğŸ’° *Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø±Ø¨Ø­/Ø§Ù„Ø®Ø³Ø§Ø±Ø©:* `{total_pnl:+.4f}`\n"
        f"ğŸ‘ *Ù…ØªÙˆØ³Ø· Ø§Ù„Ø±Ø¨Ø­:* `{avg_win:.4f}` | ğŸ‘ *Ù…ØªÙˆØ³Ø· Ø§Ù„Ø®Ø³Ø§Ø±Ø©:* `{avg_loss:.4f}`\n"
        f"âš–ï¸ *Ù…ØªÙˆØ³Ø· Ø§Ù„Ù…Ø®Ø§Ø·Ø±Ø©/Ø§Ù„Ø¹Ø§Ø¦Ø¯:* `1:{risk_reward_ratio:.2f}`\nğŸ“‰ *Ø£Ù‚ØµÙ‰ ØªØ±Ø§Ø¬Ø¹:* `-{max_drawdown:.4f}`"
    )
    return report

async def run_backtest_logic(update: Update, symbol: str, timeframe: str, limit: int):
    try:
        df = await fetch_historical_data_paginated(symbol, timeframe, limit)
        if df is None or len(df) < 50:
            await update.message.reply_text(f"Ù„Ù… Ø£ØªÙ…ÙƒÙ† Ù…Ù† Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª ÙƒØ§ÙÙŠØ© Ù„Ù€ `{symbol}`.", parse_mode=ParseMode.MARKDOWN); return

        trades = []; active_trade = None; settings = bot_data["settings"]
        for i in range(50, len(df)):
            historical_df = df.iloc[0:i].copy()
            if active_trade:
                current_candle = df.iloc[i]
                if current_candle['low'] <= active_trade['stop_loss']: active_trade.update({'exit_price': active_trade['stop_loss'], 'status': 'Stop Loss'})
                elif current_candle['high'] >= active_trade['take_profit']: active_trade.update({'exit_price': active_trade['take_profit'], 'status': 'Take Profit'})
                if 'status' in active_trade:
                    active_trade['pnl'] = (active_trade['exit_price'] - active_trade['entry_price']) * active_trade['size']
                    trades.append(active_trade); active_trade = None; continue
            
            if not active_trade:
                historical_df.ta.atr(length=settings['atr_period'], append=True)
                for scanner_name in settings['active_scanners']:
                    result = SCANNERS.get(scanner_name, lambda d, p: None)(historical_df, settings.get(scanner_name, {}))
                    if result and result.get('type') == 'long':
                        entry_price = historical_df.iloc[-1]['close']; current_atr = historical_df.iloc[-1].get(f"ATRr_{settings['atr_period']}", 0)
                        if pd.isna(current_atr) or current_atr == 0: continue
                        risk_per_unit = current_atr * settings['atr_sl_multiplier']
                        active_trade = {'entry_price': entry_price, 'stop_loss': entry_price - risk_per_unit, 'take_profit': entry_price + (risk_per_unit * settings['risk_reward_ratio']), 'size': 1, 'reason': result['reason']}
                        break
        
        report = analyze_backtest_results(trades, symbol, timeframe, limit)
        await update.message.reply_text(report, parse_mode=ParseMode.MARKDOWN)
    except Exception as e:
        logging.error(f"Error during backtest execution: {e}", exc_info=True)
        await update.message.reply_text(f"Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªØ´ØºÙŠÙ„ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±: {e}")

# --- Ø£ÙˆØ§Ù…Ø± ÙˆÙ„ÙˆØ­Ø§Øª Ù…ÙØ§ØªÙŠØ­ ØªÙ„ÙŠØ¬Ø±Ø§Ù… --- #
main_menu_keyboard = [["ğŸ“Š Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª", "ğŸ“ˆ Ø§Ù„ØµÙÙ‚Ø§Øª Ø§Ù„Ù†Ø´Ø·Ø©"], ["ğŸ§ª Ø§Ø®ØªØ¨Ø§Ø± ØªØ§Ø±ÙŠØ®ÙŠ", "âš™ï¸ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª"], ["ğŸ‘€ Ù…Ø§Ø°Ø§ ÙŠØ¬Ø±ÙŠ ÙÙŠ Ø§Ù„Ø®Ù„ÙÙŠØ©ØŸ", "â„¹ï¸ Ù…Ø³Ø§Ø¹Ø¯Ø©"]]
settings_menu_keyboard = [["ğŸ­ ØªÙØ¹ÙŠÙ„/ØªØ¹Ø·ÙŠÙ„ Ø§Ù„Ù…Ø§Ø³Ø­Ø§Øª"], ["ğŸ”§ ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ù…Ø¹Ø§ÙŠÙŠØ±", "ğŸ”™ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©"]]

async def start_command(update: Update, context: ContextTypes.DEFAULT_TYPE): await update.message.reply_text("Ø£Ù‡Ù„Ø§Ù‹ Ø¨Ùƒ ÙÙŠ Ù…Ø­Ø§ÙƒÙŠ Ø§Ù„ØªØ¯Ø§ÙˆÙ„ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…! (v12)", reply_markup=ReplyKeyboardMarkup(main_menu_keyboard, resize_keyboard=True))
async def show_settings_menu(update: Update, context: ContextTypes.DEFAULT_TYPE):
    target_message = update.message or update.callback_query.message
    await target_message.reply_text("Ø§Ø®ØªØ± Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø°ÙŠ ØªØ±ÙŠØ¯ ØªØ¹Ø¯ÙŠÙ„Ù‡:", reply_markup=ReplyKeyboardMarkup(settings_menu_keyboard, resize_keyboard=True))

def get_scanners_keyboard():
    keyboard = []
    active_scanners = bot_data["settings"].get("active_scanners", [])
    for name in SCANNERS.keys():
        status_icon = "âœ…" if name in active_scanners else "âŒ"
        button = InlineKeyboardButton(f"{status_icon} {name}", callback_data=f"toggle_{name}")
        keyboard.append([button])
    keyboard.append([InlineKeyboardButton("ğŸ”™ Ø§Ù„Ø¹ÙˆØ¯Ø© Ù„Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª", callback_data="back_to_settings")])
    return InlineKeyboardMarkup(keyboard)

async def show_scanners_menu(update: Update, context: ContextTypes.DEFAULT_TYPE):
    target_message = update.message or update.callback_query.message
    await target_message.reply_text("Ø§Ø®ØªØ± Ø§Ù„Ù…Ø§Ø³Ø­Ø§Øª Ø§Ù„ØªÙŠ ØªØ±ÙŠØ¯ ØªÙØ¹ÙŠÙ„Ù‡Ø§ Ø£Ùˆ ØªØ¹Ø·ÙŠÙ„Ù‡Ø§:", reply_markup=get_scanners_keyboard())

async def toggle_scanner_callback(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    
    # [BUG FIX] Correctly extract the full scanner name, even if it contains underscores.
    scanner_name = "_".join(query.data.split("_")[1:])
    
    active_scanners = bot_data["settings"].get("active_scanners", []).copy()
    
    if scanner_name in active_scanners:
        active_scanners.remove(scanner_name)
        logging.info(f"Deactivated scanner: {scanner_name}. New list: {active_scanners}")
    else:
        active_scanners.append(scanner_name)
        logging.info(f"Activated scanner: {scanner_name}. New list: {active_scanners}")

    bot_data["settings"]["active_scanners"] = active_scanners
    save_settings()

    try:
        await query.edit_message_text(
            text="Ø§Ø®ØªØ± Ø§Ù„Ù…Ø§Ø³Ø­Ø§Øª Ø§Ù„ØªÙŠ ØªØ±ÙŠØ¯ ØªÙØ¹ÙŠÙ„Ù‡Ø§ Ø£Ùˆ ØªØ¹Ø·ÙŠÙ„Ù‡Ø§:",
            reply_markup=get_scanners_keyboard()
        )
    except BadRequest as e:
        if "Message is not modified" in str(e):
            logging.warning(f"Ignored 'Message is not modified' error for {scanner_name}.")
        else:
            logging.error(f"A BadRequest error occurred: {e}", exc_info=True)
            raise

async def show_set_parameter_instructions(update: Update, context: ContextTypes.DEFAULT_TYPE):
    params_list = "\n".join([f"`{k}`" for k, v in bot_data["settings"].items() if not isinstance(v, (dict, list))])
    message = (f"Ù„ØªØ¹Ø¯ÙŠÙ„ Ù…Ø¹ÙŠØ§Ø±ØŒ Ø£Ø±Ø³Ù„:\n`Ø§Ø³Ù…_Ø§Ù„Ù…Ø¹ÙŠØ§Ø± = Ù‚ÙŠÙ…Ø©_Ø¬Ø¯ÙŠØ¯Ø©`\n\n*Ø§Ù„Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„ØªØ¹Ø¯ÙŠÙ„:*\n{params_list}")
    await update.message.reply_text(message, parse_mode=ParseMode.MARKDOWN, reply_markup=ReplyKeyboardMarkup([["ğŸ”™ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª"]], resize_keyboard=True))

async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE): 
    await update.message.reply_text(
        "*Ù…Ø³Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙˆØª*\n"
        "`/start` - Ø¨Ø¯Ø¡\n"
        "`/check <ID>` - Ù…ØªØ§Ø¨Ø¹Ø© ØµÙÙ‚Ø©\n"
        "`/backtest <S> <T> <C>` - Ø¥Ø¬Ø±Ø§Ø¡ Ø§Ø®ØªØ¨Ø§Ø± ØªØ§Ø±ÙŠØ®ÙŠ\n"
        "`/debug` - ÙØ­Øµ Ø­Ø§Ù„Ø© Ø§Ù„Ø¨ÙˆØª Ø§Ù„ØªØ´Ø®ÙŠØµÙŠØ©",
        parse_mode=ParseMode.MARKDOWN
    )

async def backtest_instructions_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("Ù„Ø¥Ø¬Ø±Ø§Ø¡ Ø§Ø®ØªØ¨Ø§Ø± ØªØ§Ø±ÙŠØ®ÙŠØŒ Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø£Ù…Ø± `/backtest`.\n\n"
        "ğŸ”¹ *Ø§Ù„ØµÙŠØºØ©:* `/backtest SYMBOL TIMEFRAME CANDLES`\n"
        "ğŸ”¹ *Ù…Ø«Ø§Ù„:* `/backtest BTC/USDT 1h 4000`", parse_mode=ParseMode.MARKDOWN)

async def backtest_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if len(context.args) != 3:
        await backtest_instructions_command(update, context); return
    try:
        symbol, timeframe, limit = context.args[0].upper(), context.args[1], int(context.args[2])
        await update.message.reply_text(f"â³ Ø¬Ø§Ø±ÙŠ Ø¨Ø¯Ø¡ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠ Ù„Ù€ `{symbol}`...", parse_mode=ParseMode.MARKDOWN)
        asyncio.create_task(run_backtest_logic(update, symbol, timeframe, limit))
    except (ValueError, IndexError):
        await update.message.reply_text("âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª. ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø¹Ø¯Ø¯ Ø§Ù„Ø´Ù…ÙˆØ¹ Ù‡Ùˆ Ø±Ù‚Ù… ØµØ­ÙŠØ­.")

async def stats_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    try:
        conn = sqlite3.connect(DB_FILE); cursor = conn.cursor(); cursor.execute("SELECT status, COUNT(*), SUM(pnl_usdt) FROM trades GROUP BY status"); stats_data = cursor.fetchall(); conn.close()
        counts = {s: c for s, c, p in stats_data}; pnl = {s: (p if p is not None else 0) for s, c, p in stats_data}
        total = sum(counts.values()); active = counts.get('Ù†Ø´Ø·Ø©', 0); successful = counts.get('Ù†Ø§Ø¬Ø­Ø©', 0); failed = counts.get('ÙØ§Ø´Ù„Ø©', 0)
        closed_trades = successful + failed; win_rate = (successful / closed_trades * 100) if closed_trades > 0 else 0; total_pnl = sum(pnl.values())
        stats_message = (f"*ğŸ“Š Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù…Ø­ÙØ¸Ø©*\n\nğŸ“ˆ *Ø§Ù„Ø±ØµÙŠØ¯ Ø§Ù„Ø­Ø§Ù„ÙŠ:* `${bot_data['settings']['virtual_portfolio_balance_usdt']:.2f}`\nğŸ’° *Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø±Ø¨Ø­/Ø§Ù„Ø®Ø³Ø§Ø±Ø©:* `${total_pnl:+.2f}`\n\n- *Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„ØµÙÙ‚Ø§Øª:* `{total}` (`{active}` Ù†Ø´Ø·Ø©)\n- *Ø§Ù„Ù†Ø§Ø¬Ø­Ø©:* `{successful}` | *Ø§Ù„Ø±Ø¨Ø­:* `${pnl.get('Ù†Ø§Ø¬Ø­Ø©', 0):.2f}`\n- *Ø§Ù„ÙØ§Ø´Ù„Ø©:* `{failed}` | *Ø§Ù„Ø®Ø³Ø§Ø±Ø©:* `${abs(pnl.get('ÙØ§Ø´Ù„Ø©', 0)):.2f}`\n- *Ù…Ø¹Ø¯Ù„ Ø§Ù„Ù†Ø¬Ø§Ø­:* `{win_rate:.2f}%`")
        await update.message.reply_text(stats_message, parse_mode=ParseMode.MARKDOWN)
    except Exception as e: logging.error(f"Error in stats_command: {e}", exc_info=True)

async def background_status_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    status = bot_data['status_snapshot']; next_scan_time = "N/A"
    if not status['scan_in_progress'] and context.job_queue:
        next_scan_job = context.job_queue.get_jobs_by_name('perform_scan')
        if next_scan_job and next_scan_job[0].next_t: next_scan_time = next_scan_job[0].next_t.astimezone(EGYPT_TZ).strftime('%H:%M:%S')
    message = (f"ğŸ¤– *Ø­Ø§Ù„Ø© Ø§Ù„Ø¨ÙˆØª ÙÙŠ Ø§Ù„Ø®Ù„ÙÙŠØ©*\n\n*{'ğŸŸ¢ Ø§Ù„ÙØ­Øµ Ù‚ÙŠØ¯ Ø§Ù„ØªÙ†ÙÙŠØ°...' if status['scan_in_progress'] else 'âšªï¸ Ø§Ù„Ø¨ÙˆØª ÙÙŠ ÙˆØ¶Ø¹ Ø§Ù„Ø§Ø³ØªØ¹Ø¯Ø§Ø¯'}*\n\n- *Ø¢Ø®Ø± ÙØ­Øµ Ø¨Ø¯Ø£:* `{status['last_scan_start_time']}`\n- *Ø¢Ø®Ø± ÙØ­Øµ Ø§Ù†ØªÙ‡Ù‰:* `{status['last_scan_end_time']}`\n- *Ø§Ù„Ø¹Ù…Ù„Ø§Øª Ø§Ù„Ù…ÙØ­ÙˆØµØ©:* `{status['markets_found']}`\n- *Ø§Ù„Ø¥Ø´Ø§Ø±Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©:* `{status['signals_found']}`\n- *Ø§Ù„ØµÙÙ‚Ø§Øª Ø§Ù„Ù†Ø´Ø·Ø©:* `{status['active_trades_count']}`\n- *Ø§Ù„ÙØ­Øµ Ø§Ù„ØªØ§Ù„ÙŠ:* `{next_scan_time}`")
    await update.message.reply_text(message, parse_mode=ParseMode.MARKDOWN)

async def debug_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    report_parts = ["*ğŸ” ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªØ´Ø®ÙŠØµ ÙˆØ§Ù„Ø­Ø§Ù„Ø©*"]

    # 1. Database Check
    try:
        conn = sqlite3.connect(DB_FILE)
        conn.cursor().execute("SELECT COUNT(*) FROM trades")
        conn.close()
        report_parts.append("âœ… *Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:* Ù…ØªØµÙ„Ø© ÙˆØ³Ù„ÙŠÙ…Ø©.")
    except Exception as e:
        report_parts.append(f"âŒ *Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:* ÙØ´Ù„ Ø§Ù„Ø§ØªØµØ§Ù„! ({e})")

    # 2. Exchanges Check
    exchanges_status = []
    for ex_id in EXCHANGES_TO_SCAN:
        if ex_id in bot_data.get("exchanges", {}):
            exchanges_status.append(f"  - `{ex_id}`: âœ… Ù…ØªØµÙ„")
        else:
            exchanges_status.append(f"  - `{ex_id}`: âŒ ØºÙŠØ± Ù…ØªØµÙ„")
    report_parts.append("\n*ğŸ“¡ Ø­Ø§Ù„Ø© Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø§Ù„Ù…Ù†ØµØ§Øª:*")
    report_parts.extend(exchanges_status)
    
    # 3. Job Queue Check
    report_parts.append("\n*âš™ï¸ Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ù‡Ø§Ù… Ø§Ù„Ø®Ù„ÙÙŠØ©:*")
    if context.job_queue:
        scan_job = context.job_queue.get_jobs_by_name('perform_scan')
        track_job = context.job_queue.get_jobs_by_name('track_open_trades')
        if scan_job:
            next_run = scan_job[0].next_t.astimezone(EGYPT_TZ).strftime('%H:%M:%S')
            report_parts.append(f"  - `Ù…Ù‡Ù…Ø© Ø§Ù„ÙØ­Øµ`: âœ… Ù†Ø´Ø·Ø© (Ø§Ù„ØªØ§Ù„ÙŠ: {next_run})")
        else:
            report_parts.append("  - `Ù…Ù‡Ù…Ø© Ø§Ù„ÙØ­Øµ`: âŒ ØºÙŠØ± Ù†Ø´Ø·Ø©!")

        if track_job:
            next_run = track_job[0].next_t.astimezone(EGYPT_TZ).strftime('%H:%M:%S')
            report_parts.append(f"  - `Ù…Ù‡Ù…Ø© Ø§Ù„Ù…ØªØ§Ø¨Ø¹Ø©`: âœ… Ù†Ø´Ø·Ø© (Ø§Ù„ØªØ§Ù„ÙŠ: {next_run})")
        else:
             report_parts.append("  - `Ù…Ù‡Ù…Ø© Ø§Ù„Ù…ØªØ§Ø¨Ø¹Ø©`: âŒ ØºÙŠØ± Ù†Ø´Ø·Ø©!")
    else:
        report_parts.append("  - âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ø¯ÙŠØ± Ø§Ù„Ù…Ù‡Ø§Ù…!")

    # 4. Active Scanners Check (As requested by the user)
    report_parts.append("\n*ğŸ“Š Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ø§Ø³Ø­Ø§Øª (Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ§Øª):*")
    settings = bot_data.get("settings", {})
    active_scanners = settings.get("active_scanners", [])
    for scanner in SCANNERS.keys():
        status_icon = "âœ…" if scanner in active_scanners else "âŒ"
        report_parts.append(f"  - `{scanner}`: {status_icon}")

    await update.message.reply_text("\n".join(report_parts), parse_mode=ParseMode.MARKDOWN)

async def check_trade_command(update: Update, context: ContextTypes.DEFAULT_TYPE, trade_id_from_callback=None):
    target_message = update.callback_query.message if trade_id_from_callback else update.message
    try:
        trade_id = trade_id_from_callback if trade_id_from_callback else int(context.args[0])
        conn = sqlite3.connect(DB_FILE); conn.row_factory = sqlite3.Row; cursor = conn.cursor(); cursor.execute("SELECT * FROM trades WHERE id = ?", (trade_id,)); trade = dict(cursor.fetchone()) if cursor.rowcount > 0 else None; conn.close()
        if not trade:
            await target_message.reply_text(f"Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ ØµÙÙ‚Ø© Ø¨Ø§Ù„Ø±Ù‚Ù… `{trade_id}`.", parse_mode=ParseMode.MARKDOWN)
            return
        
        message = ""
        if trade['status'] != 'Ù†Ø´Ø·Ø©':
            pnl_percent = (trade['pnl_usdt'] / trade['entry_value_usdt'] * 100) if trade['entry_value_usdt'] != 0 else 0
            closed_at_dt = datetime.strptime(trade['closed_at'], '%Y-%m-%d %H:%M:%S')
            message = f"ğŸ“‹ *Ù…Ù„Ø®Øµ Ø§Ù„ØµÙÙ‚Ø© Ø§Ù„Ù…ØºÙ„Ù‚Ø© #{trade_id}*\n\n*Ø§Ù„Ø¹Ù…Ù„Ø©:* `{trade['symbol']}`\n*Ø§Ù„Ø­Ø§Ù„Ø©:* `{trade['status']}`\n*ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¥ØºÙ„Ø§Ù‚:* `{closed_at_dt.strftime('%Y-%m-%d %I:%M %p')}`\n*Ø§Ù„Ø±Ø¨Ø­/Ø§Ù„Ø®Ø³Ø§Ø±Ø©:* `${trade['pnl_usdt']:+.2f} ({pnl_percent:+.2f}%)`"
        else:
            exchange = bot_data["exchanges"].get(trade['exchange'].lower())
            if not exchange: await target_message.reply_text("Ø§Ù„Ù…Ù†ØµØ© ØºÙŠØ± Ù…ØªØµÙ„Ø© Ø­Ø§Ù„ÙŠØ§Ù‹."); return
            ticker = await exchange.fetch_ticker(trade['symbol']); current_price = ticker.get('last') or ticker.get('close')
            live_pnl = (current_price - trade['entry_price']) * trade['quantity']; live_pnl_percent = (live_pnl / trade['entry_value_usdt'] * 100) if trade['entry_value_usdt'] != 0 else 0
            message = f"ğŸ“ˆ *Ù…ØªØ§Ø¨Ø¹Ø© Ø­ÙŠØ© Ù„Ù„ØµÙÙ‚Ø© #{trade_id}*\n\n*Ø§Ù„Ø¹Ù…Ù„Ø©:* `{trade['symbol']}`\n*Ø§Ù„Ø­Ø§Ù„Ø©:* `Ù†Ø´Ø·Ø©`\n\n*Ø³Ø¹Ø± Ø§Ù„Ø¯Ø®ÙˆÙ„:* `${trade['entry_price']:,.4f}`\n*Ø§Ù„Ø³Ø¹Ø± Ø§Ù„Ø­Ø§Ù„ÙŠ:* `${current_price:,.4f}`\n\nğŸ’° *Ø§Ù„Ø±Ø¨Ø­/Ø§Ù„Ø®Ø³Ø§Ø±Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ©:*\n`${live_pnl:+.2f} ({live_pnl_percent:+.2f}%)`"
        
        await target_message.reply_text(message, parse_mode=ParseMode.MARKDOWN)
    except (ValueError, IndexError): await target_message.reply_text("Ø±Ù‚Ù… ØµÙÙ‚Ø© ØºÙŠØ± ØµØ§Ù„Ø­. Ù…Ø«Ø§Ù„: `/check 17`")
    except Exception as e: logging.error(f"Error in check_trade_command: {e}", exc_info=True)

async def show_active_trades_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    conn = sqlite3.connect(DB_FILE); conn.row_factory = sqlite3.Row; cursor = conn.cursor()
    cursor.execute("SELECT id, symbol FROM trades WHERE status = 'Ù†Ø´Ø·Ø©' ORDER BY id DESC")
    active_trades = cursor.fetchall(); conn.close()
    if not active_trades:
        await update.message.reply_text("Ù„Ø§ ØªÙˆØ¬Ø¯ ØµÙÙ‚Ø§Øª Ù†Ø´Ø·Ø© Ø­Ø§Ù„ÙŠØ§Ù‹."); return
    keyboard = [[InlineKeyboardButton(f"ID: {t['id']} | {t['symbol']}", callback_data=f"check_{t['id']}")] for t in active_trades]
    await update.message.reply_text("Ø§Ø®ØªØ± ØµÙÙ‚Ø© Ù„Ù…ØªØ§Ø¨Ø¹ØªÙ‡Ø§ Ù…Ø¨Ø§Ø´Ø±Ø©:", reply_markup=InlineKeyboardMarkup(keyboard))

async def button_callback_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    await query.answer()

    data = query.data
    if data.startswith("toggle_"):
        await toggle_scanner_callback(update, context)
    elif data == "back_to_settings":
        await query.message.delete()
        await context.bot.send_message(
            chat_id=query.message.chat_id,
            text="Ø§Ø®ØªØ± Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø°ÙŠ ØªØ±ÙŠØ¯ ØªØ¹Ø¯ÙŠÙ„Ù‡:",
            reply_markup=ReplyKeyboardMarkup(settings_menu_keyboard, resize_keyboard=True)
        )
    elif data.startswith("check_"):
        await check_trade_command(update, context, trade_id_from_callback=int(data.split("_")[1]))

async def main_text_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    handlers = {
        "ğŸ“Š Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª": stats_command, "ğŸ“ˆ Ø§Ù„ØµÙÙ‚Ø§Øª Ø§Ù„Ù†Ø´Ø·Ø©": show_active_trades_command,
        "â„¹ï¸ Ù…Ø³Ø§Ø¹Ø¯Ø©": help_command, "ğŸ§ª Ø§Ø®ØªØ¨Ø§Ø± ØªØ§Ø±ÙŠØ®ÙŠ": backtest_instructions_command,
        "âš™ï¸ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª": show_settings_menu, "ğŸ‘€ Ù…Ø§Ø°Ø§ ÙŠØ¬Ø±ÙŠ ÙÙŠ Ø§Ù„Ø®Ù„ÙÙŠØ©ØŸ": background_status_command,
        "ğŸ”§ ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ù…Ø¹Ø§ÙŠÙŠØ±": show_set_parameter_instructions, "ğŸ”™ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©": start_command,
        "ğŸ”™ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª": show_settings_menu, "ğŸ­ ØªÙØ¹ÙŠÙ„/ØªØ¹Ø·ÙŠÙ„ Ø§Ù„Ù…Ø§Ø³Ø­Ø§Øª": show_scanners_menu
    }
    text = update.message.text
    if text in handlers: await handlers[text](update, context)
    elif re.match(r"^\s*(\w+)\s*=\s*(.+)\s*$", text):
        match = re.match(r"^\s*(\w+)\s*=\s*(.+)\s*$", text); param, value_str = match.groups()
        settings = bot_data["settings"]
        if param in settings and not isinstance(settings[param], (dict, list)):
            try:
                current_value = settings[param]
                if isinstance(current_value, bool): new_value = value_str.lower() in ['true', '1', 'yes', 'on']
                elif isinstance(current_value, int): new_value = int(value_str)
                else: new_value = float(value_str)
                settings[param] = new_value; save_settings()
                await update.message.reply_text(f"âœ… ØªÙ… ØªØ­Ø¯ÙŠØ« `{param}` Ø¥Ù„Ù‰ `{new_value}`.")
            except ValueError: await update.message.reply_text(f"âŒ Ù‚ÙŠÙ…Ø© ØºÙŠØ± ØµØ§Ù„Ø­Ø©.")
        else: await update.message.reply_text(f"âŒ Ø®Ø·Ø£: Ø§Ù„Ù…Ø¹ÙŠØ§Ø± `{param}` ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ Ø£Ùˆ Ù„Ø§ ÙŠÙ…ÙƒÙ† ØªØ¹Ø¯ÙŠÙ„Ù‡ Ø¨Ù‡Ø°Ù‡ Ø§Ù„Ø·Ø±ÙŠÙ‚Ø©.")

async def error_handler(update: object, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Log Errors caused by Updates."""
    logging.error(f"Exception while handling an update: {context.error}", exc_info=context.error)

async def post_init(application: Application):
    logging.info("Post-init started. Initializing exchanges...")
    await initialize_exchanges()
    if not bot_data["exchanges"]:
        logging.critical("CRITICAL: Failed to connect during post_init.")
        return

    logging.info("Exchanges initialized. Setting up job queue...")
    if application.job_queue:
        logging.info("Job queue found. Scheduling jobs.")
        application.job_queue.run_repeating(perform_scan, interval=SCAN_INTERVAL_SECONDS, first=10, name='perform_scan')
        application.job_queue.run_repeating(track_open_trades, interval=TRACK_INTERVAL_SECONDS, first=20, name='track_open_trades')
        logging.info("Jobs scheduled successfully.")
    else:
        logging.error("Job queue not found in application object!")
    
    await application.bot.send_message(chat_id=TELEGRAM_CHAT_ID, text=f"ğŸš€ *Ù…Ø­Ø§ÙƒÙŠ Ø§Ù„ØªØ¯Ø§ÙˆÙ„ Ø§Ù„Ù…ØªÙ‚Ø¯Ù… (v12) Ø¬Ø§Ù‡Ø² Ù„Ù„Ø¹Ù…Ù„!*", parse_mode=ParseMode.MARKDOWN)
    logging.info("Post-init finished.")

async def post_shutdown(application: Application): await asyncio.gather(*[ex.close() for ex in bot_data["exchanges"].values()]); logging.info("Connections closed.")

def main():
    print("ğŸš€ Starting Pro Trading Simulator Bot (v12)...")
    load_settings(); init_database()
    application = Application.builder().token(TELEGRAM_BOT_TOKEN).post_init(post_init).post_shutdown(post_shutdown).build()
    
    # Add handlers
    application.add_handler(CommandHandler("start", start_command))
    application.add_handler(CommandHandler("check", check_trade_command))
    application.add_handler(CommandHandler("backtest", backtest_command))
    application.add_handler(CommandHandler("debug", debug_command))
    application.add_handler(CallbackQueryHandler(button_callback_handler))
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, main_text_handler))
    
    # Add error handler
    application.add_error_handler(error_handler)
    
    print("âœ… Bot is now running and polling for updates...")
    application.run_polling()

if __name__ == '__main__':
    try: main()
    except Exception as e: logging.critical(f"Bot stopped due to a critical error in __main__: {e}", exc_info=True)

